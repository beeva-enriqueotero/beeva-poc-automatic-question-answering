# beeva-poc-automatic-question-answering
Proof of Concept with Automatic Question Answering and Question Generation

## Question Generation
### Experiment 1: Use NLP to generate "fill the gap" questionnaires from Wikipedia.

NLP Tools: *Python3, NLTK, TextBlob, (Multilingual) WordNet*
Process
- Segment into sentences with TextBlob Tokenizer
- Filter sentences with simple rules
- Select a common noun per sentence with Part of Speech (PoS) Tagger
  - **English**: *TextBlob PatternParser* (Penn Treebank tagset)
  - **Spanish**: *spaghetti-tagger* (EAGLES tagset). *Note*: Pattern supports Spanish, but not python3
- Generate distractors with *WordNet*

* See https://github.com/beeva-enriqueotero/wikipedia-question-generator
* Based on https://github.com/atbaker/wikipedia-question-generator


### Old dummy version
```
python mvp.py
# Usage: python mvp.py <word_to_search_in_wikipedia> <number_of_sentences>
python mvp.py Isabel 1
# Output: This set of names is a southwestern European variant of the ... name Elisheva, also represented in English and other western languages as Elizabeth
# Missing word: Hebrew
```

## Question Answering

### Experiment 2: Fill The Gaps 
Answer fill-the-gap questions on multi-choice tests. Same as generated by experiment 1. In order to filter easy questions.
* a) With *Word Embeddings*: using gensim's [`predict_output_word`](https://github.com/RaRe-Technologies/gensim/blob/4a3b2137ce3c2c8fc83a7e8e0921991e1862e9c4/gensim/models/word2vec.py#L1286) implementation. Released on v2.1.0 (2017/05/12)
* b) With *Ngrams*: using (English) 2-grams from 2009 Google collection. See [notebook](ngrams_demo.ipynb) for details.

#### Results:
* a) gensim's word2vec fails. `predict_output_word` is not better than random guess for this task. Note: not precise enough to complete easy phrases as *El Rey [...] Carlos I*. Moreover `doesnt_match` alternative fails for this task too.
* b) 2grams accuracy: between 49% and 55%.

#### Conclusions:
* Simple Ngrams (2grams) get much better accuracy than random guess.
* gensim's Word2vec `predict_output_word` fails for this task. Not better than random guess.
* gensim's Word2vec `doesnt_match` alternative is not useful for this task too.

*Notes about pretrained Word Embeddings on Gensim*: 
   * [Spanish Billion Words Corpus](http://crscardellino.me/SBWCE/) trained models don't work with `predict_output_word`. You need to train word2vec with negative > 0 for this to work. 
   * Moreover FastText wrapper don't work with `predict_output_word`, and it gets [errors](https://github.com/RaRe-Technologies/gensim/issues/1343) with other typical methods

### Experiment 3: Test MS-Cognitive https://qnamaker.ai/: From FAQ to Bot in minutes
* Example [Spanish FAQs](https://aws.amazon.com/es/ec2/faqs/)
* Example [questions](https://github.com/beeva-enriqueotero/beeva-poc-automatic-question-answering/blob/master/data/test_qnamaker_spanish.txt)

#### Results:
* 17/40 right 
* 11/40 related
* 30% fails!

#### Conclusions:
* qnamaker.ai is not state-of-the-art technology, despite it is beta.
* qnamaker.ai is based on "index & rank". Old techniques from Information Retrieval in 70s. Similar to Solr or ElasticSearch
