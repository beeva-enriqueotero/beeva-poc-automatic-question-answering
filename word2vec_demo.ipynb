{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import re, unicodedata, logging, string\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Word embeddings (word2vec) to automagically fill the gaps\n",
    "* Spanish model trained with 80M from wikipedia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH='/home/enriqueotero/datasets/nlp/wikipedia/data/'\n",
    "\n",
    "# wikipedia_es_small > 80M words\n",
    "fileToRead = PATH+'wikipedia_es_small.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "print \"File:\"\n",
    "print fileToRead\n",
    "\n",
    "def clean(x):\n",
    "   x = unicodedata.normalize('NFKD', x).encode('ascii','ignore').lower()\n",
    "   replace_punctuation = string.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "   x = x.translate(replace_punctuation)\n",
    "   x = re.sub('@%$&[\\n/:!,;)()_?¿¡<>]', ' ', x)\n",
    "   x = re.sub(' - ', ' ', x)\n",
    "   x = re.sub(' +',' ', x).strip()\n",
    "   return x\n",
    "    \n",
    "sentences = []\n",
    "with open(fileToRead, 'r') as fileData:\n",
    "    for lineas in fileData:\n",
    "        #Formatear linea si hace falta aquí\n",
    "        lineArray = lineas.split(\".\")\n",
    "        for line in lineArray:\n",
    "            if len(line) > 1:\n",
    "                line = line.decode('utf-8')\n",
    "                line = clean(line) # ¿? problemas con gensim y tildes y eñes...\n",
    "                if len(line) > 1:\n",
    "                    sentences.append(line.split(\" \"))\n",
    "    fileData.close()\n",
    "\n",
    "\n",
    "print \"\\nNumber of sentences\"             \n",
    "print len(sentences)\n",
    "\n",
    "done = time.time()\n",
    "elapsed = done - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "model = gensim.models.Word2Vec(sentences, size=100, workers=3, negative=1, sg=1)\n",
    "\n",
    "done = time.time()\n",
    "elapsed = done - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gensim.models.Word2Vec.save(model,'wikipedia_model_es')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And load model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And load model again\n",
    "FILENAME = 'wikipedia_model_es'\n",
    "model = gensim.models.Word2Vec.load(FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try some typical phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rey', 0.00019195296), ('ii', 0.00015460837), ('iii', 0.00011868595), ('iv', 0.00011611087), ('i', 0.00011187967), ('duque', 0.00010843632), ('principe', 0.00010823992), ('felipe', 0.00010768851), ('conde', 0.00010714246), ('castilla', 0.00010646953)]\n"
     ]
    }
   ],
   "source": [
    "words = \"el rey juan carlos y la reina\".split()\n",
    "print(model.predict_output_word(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove existing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ii', 0.00015460837), ('iii', 0.00011868595), ('iv', 0.00011611087), ('i', 0.00011187967), ('duque', 0.00010843632), ('principe', 0.00010823992), ('felipe', 0.00010768851), ('conde', 0.00010714246), ('castilla', 0.00010646953)]\n"
     ]
    }
   ],
   "source": [
    "words = \"el rey juan carlos y la reina\".split()\n",
    "output = model.predict_output_word(words)\n",
    "output = [x for x in output if x[0] not in words]\n",
    "print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('temporadas', 7.6493874e-05), ('muy', 6.8064357e-05), ('desde', 6.0666782e-05), ('mantuvo', 5.8725513e-05), ('ventas', 5.7498029e-05), ('sus', 5.675741e-05), ('pero', 5.4015534e-05), ('tierras', 5.2203679e-05)]\n"
     ]
    }
   ],
   "source": [
    "words = \"buenas y hasta mañana\".split()\n",
    "output = model.predict_output_word(words)\n",
    "output = [x for x in output if x[0] not in words]\n",
    "print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('programacion', 9.2945374e-05), ('otros', 8.1234597e-05), ('sistemas', 7.485925e-05), ('software', 7.3789241e-05), ('son', 7.3208372e-05), ('archivos', 7.3128169e-05), ('algunos', 7.117918e-05), ('java', 6.9016751e-05), ('datos', 6.9002206e-05)]\n"
     ]
    }
   ],
   "source": [
    "words = \"informática y lenguajes de\".split()\n",
    "output = model.predict_output_word(words)\n",
    "output = [x for x in output if x[0] not in words]\n",
    "print output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try actual fill-the-gap questions. \n",
    "Generated with `wikitrivia --lang es 'Fernando VII'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('parte', 5.6180288e-05), ('lo', 5.1669511e-05), ('mas', 4.5763965e-05), ('contra', 4.5105324e-05), ('partido', 4.4790893e-05), ('pero', 4.4231358e-05), ('sobre', 4.3421747e-05), ('era', 4.308984e-05), ('gran', 4.1953499e-05), ('frente', 4.17138e-05)]\n"
     ]
    }
   ],
   "source": [
    "words = \"La última fase de su reinado, la llamada Década Ominosa, se caracterizó por una feroz de los exaltados, acompañada de una política absolutista moderada o incluso liberaldoctrinaria que provocó un profundo descontento en los círculos absolutistas, que formaron partido en torno al infante Carlos María Isidro\".split()\n",
    "print(model.predict_output_word(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233361\n",
      "[('represion', 2.8628981e-05), ('parada', 1.4828272e-05), ('proyeccion', 1.1659075e-05), ('negacion', 1.0614357e-05), ('descalificacion', 5.8318933e-06)]\n"
     ]
    }
   ],
   "source": [
    "words = \"La última fase de su reinado, la llamada Década Ominosa, se caracterizó por una feroz de los exaltados, acompañada de una política absolutista moderada o incluso liberaldoctrinaria que provocó un profundo descontento en los círculos absolutistas, que formaron partido en torno al infante Carlos María Isidro\".split()\n",
    "output = model.predict_output_word(words, topn=1000000)\n",
    "print len(output)\n",
    "output = [x for x in output if x[0] in [\"represion\", \"parada\", \"descalificacion\", \"negacion\", \"proyeccion\"]]\n",
    "print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "words = \"una sin escrupulos vengativa y traicionera\".split()\n",
    "output = model.predict_output_word(words, topn=1000000)\n",
    "output = [x for x in output if x[0] in [\"persona, amenaza, amistad, fauna, flora\"]]\n",
    "print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233361\n",
      "[('represion', 4.7717975e-05), ('parada', 1.4552617e-05), ('negacion', 1.3123062e-05), ('proyeccion', 9.3422059e-06), ('descalificacion', 4.9355567e-06)]\n"
     ]
    }
   ],
   "source": [
    "words = \"una feroz de los exaltados\".split()\n",
    "output = model.predict_output_word(words, topn=1000000)\n",
    "print len(output)\n",
    "choices = [\"represion\", \"parada\", \"descalificacion\", \"negacion\", \"proyeccion\"]\n",
    "output = [x for x in output if x[0] in choices]\n",
    "if len(output) == 0:\n",
    "    output = random.choice(choices)\n",
    "print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 31 questions\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "jsonfile = 'data/historia_i.json'\n",
    "\n",
    "def json_to_dict(filename):\n",
    "    with open(filename) as json_data:\n",
    "        d = json.load(json_data)\n",
    "    return d\n",
    "\n",
    "d = json_to_dict(jsonfile)\n",
    "N = len(d)\n",
    "print \"Analyzing {} questions\".format(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def get_correct_answers(d):\n",
    "    correct = 0.0\n",
    "    for question in d:\n",
    "\n",
    "        answer = \"WRONG! \"\n",
    "        myquestion = question[\"question\"].replace(\"__________\", \"{}\")\n",
    "   \n",
    "        choices = [question[\"answer\"]]\n",
    "        choices.extend(question[\"similar_words\"])\n",
    "    \n",
    "        output = model.predict_output_word(words, topn=1000000)\n",
    "        output = [x for x in output if x[0] in choices]\n",
    "        if len(output) == 0:\n",
    "            output = random.choice(choices)\n",
    "        else:\n",
    "            output = output[0]\n",
    "        #print output[0]\n",
    "       \n",
    "        if (output[0] == choices[0]):\n",
    "            correct+=1\n",
    "            answer = \"RIGHT! \"\n",
    "\n",
    "    #print \"Choices: {}\".format(map(str,choices))\n",
    "    \n",
    "    return correct\n",
    "\n",
    "correct = get_correct_answers(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 11/31 = 35.48%\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy = %i/%i = %.2f%%\" %(correct, N, 100*correct/N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "word2vec",
   "language": "python",
   "name": "word2vec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
